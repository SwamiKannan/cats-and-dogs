{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms,models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms=transforms.Compose([transforms.ToTensor(), # Need to run Part 1 of the image transforms before this\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "test_transforms=transforms.Compose([transforms.Resize(224), \n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                         [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CAT', 'DOG']\n"
     ]
    }
   ],
   "source": [
    "path = '..\\\\Data\\\\CATS_DOGS\\\\'\n",
    "train_data=datasets.ImageFolder(root=path+'train1',transform=train_transforms)\n",
    "test_data=datasets.ImageFolder(root=path+'test',transform=test_transforms)\n",
    "\n",
    "labels=train_data.classes\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_data,shuffle=True, batch_size=500, num_workers=4)\n",
    "test_loader=DataLoader(test_data,shuffle=False, batch_size=10, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model=models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9408\n",
      "64\n",
      "64\n",
      "4096\n",
      "64\n",
      "64\n",
      "36864\n",
      "64\n",
      "64\n",
      "16384\n",
      "256\n",
      "256\n",
      "16384\n",
      "256\n",
      "256\n",
      "16384\n",
      "64\n",
      "64\n",
      "36864\n",
      "64\n",
      "64\n",
      "16384\n",
      "256\n",
      "256\n",
      "16384\n",
      "64\n",
      "64\n",
      "36864\n",
      "64\n",
      "64\n",
      "16384\n",
      "256\n",
      "256\n",
      "32768\n",
      "128\n",
      "128\n",
      "147456\n",
      "128\n",
      "128\n",
      "65536\n",
      "512\n",
      "512\n",
      "131072\n",
      "512\n",
      "512\n",
      "65536\n",
      "128\n",
      "128\n",
      "147456\n",
      "128\n",
      "128\n",
      "65536\n",
      "512\n",
      "512\n",
      "65536\n",
      "128\n",
      "128\n",
      "147456\n",
      "128\n",
      "128\n",
      "65536\n",
      "512\n",
      "512\n",
      "65536\n",
      "128\n",
      "128\n",
      "147456\n",
      "128\n",
      "128\n",
      "65536\n",
      "512\n",
      "512\n",
      "131072\n",
      "256\n",
      "256\n",
      "589824\n",
      "256\n",
      "256\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "524288\n",
      "1024\n",
      "1024\n",
      "262144\n",
      "256\n",
      "256\n",
      "589824\n",
      "256\n",
      "256\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "262144\n",
      "256\n",
      "256\n",
      "589824\n",
      "256\n",
      "256\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "262144\n",
      "256\n",
      "256\n",
      "589824\n",
      "256\n",
      "256\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "262144\n",
      "256\n",
      "256\n",
      "589824\n",
      "256\n",
      "256\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "262144\n",
      "256\n",
      "256\n",
      "589824\n",
      "256\n",
      "256\n",
      "262144\n",
      "1024\n",
      "1024\n",
      "524288\n",
      "512\n",
      "512\n",
      "2359296\n",
      "512\n",
      "512\n",
      "1048576\n",
      "2048\n",
      "2048\n",
      "2097152\n",
      "2048\n",
      "2048\n",
      "1048576\n",
      "512\n",
      "512\n",
      "2359296\n",
      "512\n",
      "512\n",
      "1048576\n",
      "2048\n",
      "2048\n",
      "1048576\n",
      "512\n",
      "512\n",
      "2359296\n",
      "512\n",
      "512\n",
      "1048576\n",
      "2048\n",
      "2048\n",
      "2048000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for params in resnet50_model.parameters():\n",
    "    print(params.numel())\n",
    "    params.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=84, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=84, out_features=2, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_model.fc=nn.Sequential(nn.Linear(2048,84),nn.ReLU(),nn.Dropout(0.4),nn.Linear(84,2),nn.LogSoftmax(dim=1))\n",
    "resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(resnet50_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for epoch 0 and batch  20, training loss = 0.15009073913097382 and the accuracy=87.52999877929688\n",
      " for epoch 0 and batch  40, training loss = 0.09942071884870529 and the accuracy=91.3550033569336\n",
      " for epoch 0 and batch  60, training loss = 0.11880755424499512 and the accuracy=92.89666748046875\n",
      " for epoch 0 and batch  20, test loss = 1.4810158014297485 and the accuracy=56.5\n",
      " for epoch 0 and batch  40, test loss = 1.9542768001556396 and the accuracy=56.5\n",
      " for epoch 0 and batch  60, test loss = 0.9176396131515503 and the accuracy=55.66666793823242\n",
      " for epoch 0 and batch  80, test loss = 1.2678539752960205 and the accuracy=54.875\n",
      " for epoch 0 and batch  100, test loss = 1.3066078424453735 and the accuracy=55.099998474121094\n",
      " for epoch 0 and batch  120, test loss = 1.380629539489746 and the accuracy=55.25\n",
      " for epoch 0 and batch  140, test loss = 1.786214828491211 and the accuracy=55.57143020629883\n",
      " for epoch 0 and batch  160, test loss = 1.2312467098236084 and the accuracy=55.625\n",
      " for epoch 0 and batch  180, test loss = 1.5767762660980225 and the accuracy=55.66666793823242\n",
      " for epoch 0 and batch  200, test loss = 1.144179105758667 and the accuracy=55.54999923706055\n",
      " for epoch 0 and batch  220, test loss = 0.9945578575134277 and the accuracy=55.59090805053711\n",
      " for epoch 0 and batch  240, test loss = 1.9374465942382812 and the accuracy=55.83333206176758\n",
      " for epoch 0 and batch  260, test loss = 1.2844703197479248 and the accuracy=55.730770111083984\n",
      " for epoch 0 and batch  280, test loss = 1.3656713962554932 and the accuracy=55.89285659790039\n",
      " for epoch 0 and batch  300, test loss = 1.3385804891586304 and the accuracy=55.93333435058594\n",
      " for epoch 0 and batch  320, test loss = 1.2770411968231201 and the accuracy=55.96875\n",
      " for epoch 0 and batch  340, test loss = 1.7507623434066772 and the accuracy=55.764705657958984\n",
      " for epoch 0 and batch  360, test loss = 1.3112480640411377 and the accuracy=55.83333206176758\n",
      " for epoch 0 and batch  380, test loss = 1.2362996339797974 and the accuracy=55.842105865478516\n",
      " for epoch 0 and batch  400, test loss = 1.4799026250839233 and the accuracy=55.75\n",
      " for epoch 0 and batch  420, test loss = 1.3144911527633667 and the accuracy=55.69047546386719\n",
      " for epoch 0 and batch  440, test loss = 1.540963888168335 and the accuracy=55.727272033691406\n",
      " for epoch 0 and batch  460, test loss = 1.412339448928833 and the accuracy=55.58695602416992\n",
      " for epoch 0 and batch  480, test loss = 1.3451954126358032 and the accuracy=55.54166793823242\n",
      " for epoch 0 and batch  500, test loss = 1.3537787199020386 and the accuracy=55.459999084472656\n",
      " for epoch 0 and batch  520, test loss = 1.6345436573028564 and the accuracy=55.403846740722656\n",
      " for epoch 0 and batch  540, test loss = 1.4937396049499512 and the accuracy=55.407405853271484\n",
      " for epoch 0 and batch  560, test loss = 1.5609384775161743 and the accuracy=55.375\n",
      " for epoch 0 and batch  580, test loss = 1.6471383571624756 and the accuracy=55.2931022644043\n",
      " for epoch 0 and batch  600, test loss = 1.5547939538955688 and the accuracy=55.266666412353516\n",
      " for epoch 0 and batch  620, test loss = 1.4422497749328613 and the accuracy=55.25806427001953\n",
      " for epoch 1 and batch  20, training loss = 0.08364865928888321 and the accuracy=95.97000122070312\n",
      " for epoch 1 and batch  40, training loss = 0.10720333456993103 and the accuracy=96.12999725341797\n",
      " for epoch 1 and batch  60, training loss = 0.07121361047029495 and the accuracy=95.89666748046875\n",
      " for epoch 1 and batch  20, test loss = 1.122018575668335 and the accuracy=68.0\n",
      " for epoch 1 and batch  40, test loss = 1.2283351421356201 and the accuracy=65.75\n",
      " for epoch 1 and batch  60, test loss = 0.8382766842842102 and the accuracy=65.33333587646484\n",
      " for epoch 1 and batch  80, test loss = 0.9605002403259277 and the accuracy=64.25\n",
      " for epoch 1 and batch  100, test loss = 0.866297721862793 and the accuracy=64.5999984741211\n",
      " for epoch 1 and batch  120, test loss = 1.1969122886657715 and the accuracy=64.75\n",
      " for epoch 1 and batch  140, test loss = 1.3866523504257202 and the accuracy=65.14286041259766\n",
      " for epoch 1 and batch  160, test loss = 1.1467036008834839 and the accuracy=65.0\n",
      " for epoch 1 and batch  180, test loss = 1.1684125661849976 and the accuracy=65.05555725097656\n",
      " for epoch 1 and batch  200, test loss = 0.9758747220039368 and the accuracy=64.9000015258789\n",
      " for epoch 1 and batch  220, test loss = 0.5448079109191895 and the accuracy=64.7272720336914\n",
      " for epoch 1 and batch  240, test loss = 1.4171409606933594 and the accuracy=64.79166412353516\n",
      " for epoch 1 and batch  260, test loss = 0.9513657689094543 and the accuracy=64.73076629638672\n",
      " for epoch 1 and batch  280, test loss = 1.0554909706115723 and the accuracy=64.78571319580078\n",
      " for epoch 1 and batch  300, test loss = 0.9543172717094421 and the accuracy=64.86666870117188\n",
      " for epoch 1 and batch  320, test loss = 1.7312618494033813 and the accuracy=64.46875\n",
      " for epoch 1 and batch  340, test loss = 2.0205867290496826 and the accuracy=63.29411697387695\n",
      " for epoch 1 and batch  360, test loss = 1.6514785289764404 and the accuracy=62.47222137451172\n",
      " for epoch 1 and batch  380, test loss = 1.9655179977416992 and the accuracy=61.605262756347656\n",
      " for epoch 1 and batch  400, test loss = 1.7774255275726318 and the accuracy=60.75\n",
      " for epoch 1 and batch  420, test loss = 1.712385892868042 and the accuracy=60.119049072265625\n",
      " for epoch 1 and batch  440, test loss = 2.045020341873169 and the accuracy=59.522727966308594\n",
      " for epoch 1 and batch  460, test loss = 1.5149059295654297 and the accuracy=59.0\n",
      " for epoch 1 and batch  480, test loss = 1.9744316339492798 and the accuracy=58.47916793823242\n",
      " for epoch 1 and batch  500, test loss = 1.8224176168441772 and the accuracy=57.959999084472656\n",
      " for epoch 1 and batch  520, test loss = 2.39987850189209 and the accuracy=57.44230651855469\n",
      " for epoch 1 and batch  540, test loss = 2.166125535964966 and the accuracy=57.092594146728516\n",
      " for epoch 1 and batch  560, test loss = 2.1734402179718018 and the accuracy=56.83928680419922\n",
      " for epoch 1 and batch  580, test loss = 2.117313861846924 and the accuracy=56.482757568359375\n",
      " for epoch 1 and batch  600, test loss = 2.4955615997314453 and the accuracy=56.03333282470703\n",
      " for epoch 1 and batch  620, test loss = 1.8323047161102295 and the accuracy=55.75806427001953\n",
      " for epoch 2 and batch  20, training loss = 0.13093335926532745 and the accuracy=95.80999755859375\n",
      " for epoch 2 and batch  40, training loss = 0.0806763544678688 and the accuracy=96.09500122070312\n",
      " for epoch 2 and batch  60, training loss = 0.13425394892692566 and the accuracy=96.18000030517578\n",
      " for epoch 2 and batch  20, test loss = 1.4508349895477295 and the accuracy=61.0\n",
      " for epoch 2 and batch  40, test loss = 1.544182538986206 and the accuracy=60.0\n",
      " for epoch 2 and batch  60, test loss = 0.9924657940864563 and the accuracy=60.33333206176758\n",
      " for epoch 2 and batch  80, test loss = 1.1590520143508911 and the accuracy=60.0\n",
      " for epoch 2 and batch  100, test loss = 0.8930379152297974 and the accuracy=59.79999923706055\n",
      " for epoch 2 and batch  120, test loss = 1.6260535717010498 and the accuracy=60.5\n",
      " for epoch 2 and batch  140, test loss = 1.463646411895752 and the accuracy=60.78571319580078\n",
      " for epoch 2 and batch  160, test loss = 1.322247862815857 and the accuracy=60.375\n",
      " for epoch 2 and batch  180, test loss = 1.1349611282348633 and the accuracy=60.66666793823242\n",
      " for epoch 2 and batch  200, test loss = 1.4150604009628296 and the accuracy=60.70000076293945\n",
      " for epoch 2 and batch  220, test loss = 0.7779154777526855 and the accuracy=60.727272033691406\n",
      " for epoch 2 and batch  240, test loss = 1.601999044418335 and the accuracy=60.83333206176758\n",
      " for epoch 2 and batch  260, test loss = 0.9347596168518066 and the accuracy=60.96154022216797\n",
      " for epoch 2 and batch  280, test loss = 0.973400890827179 and the accuracy=61.10714340209961\n",
      " for epoch 2 and batch  300, test loss = 1.0505861043930054 and the accuracy=61.233333587646484\n",
      " for epoch 2 and batch  320, test loss = 1.6787710189819336 and the accuracy=61.0625\n",
      " for epoch 2 and batch  340, test loss = 1.6893301010131836 and the accuracy=60.32352828979492\n",
      " for epoch 2 and batch  360, test loss = 1.530017614364624 and the accuracy=59.80555725097656\n",
      " for epoch 2 and batch  380, test loss = 1.4792659282684326 and the accuracy=59.31578826904297\n",
      " for epoch 2 and batch  400, test loss = 1.5532701015472412 and the accuracy=58.849998474121094\n",
      " for epoch 2 and batch  420, test loss = 1.7703301906585693 and the accuracy=58.404762268066406\n",
      " for epoch 2 and batch  440, test loss = 2.1023454666137695 and the accuracy=58.0\n",
      " for epoch 2 and batch  460, test loss = 1.5820131301879883 and the accuracy=57.69565200805664\n",
      " for epoch 2 and batch  480, test loss = 1.8650684356689453 and the accuracy=57.25\n",
      " for epoch 2 and batch  500, test loss = 2.006779193878174 and the accuracy=56.86000061035156\n",
      " for epoch 2 and batch  520, test loss = 2.135333776473999 and the accuracy=56.519229888916016\n",
      " for epoch 2 and batch  540, test loss = 1.692234992980957 and the accuracy=56.407405853271484\n",
      " for epoch 2 and batch  560, test loss = 1.865058183670044 and the accuracy=56.25\n",
      " for epoch 2 and batch  580, test loss = 1.835479497909546 and the accuracy=56.08620834350586\n",
      " for epoch 2 and batch  600, test loss = 2.0252392292022705 and the accuracy=55.83333206176758\n",
      " for epoch 2 and batch  620, test loss = 1.7062572240829468 and the accuracy=55.69355010986328\n",
      " for epoch 3 and batch  20, training loss = 0.08525893837213516 and the accuracy=96.69000244140625\n",
      " for epoch 3 and batch  40, training loss = 0.06236240267753601 and the accuracy=96.6449966430664\n",
      " for epoch 3 and batch  60, training loss = 0.07258539646863937 and the accuracy=96.63999938964844\n",
      " for epoch 3 and batch  20, test loss = 1.3817856311798096 and the accuracy=65.5\n",
      " for epoch 3 and batch  40, test loss = 1.4328457117080688 and the accuracy=64.25\n",
      " for epoch 3 and batch  60, test loss = 0.9415108561515808 and the accuracy=63.83333206176758\n",
      " for epoch 3 and batch  80, test loss = 0.7356191873550415 and the accuracy=62.875\n",
      " for epoch 3 and batch  100, test loss = 0.8044265508651733 and the accuracy=62.900001525878906\n",
      " for epoch 3 and batch  120, test loss = 1.3827574253082275 and the accuracy=63.0\n",
      " for epoch 3 and batch  140, test loss = 1.279348611831665 and the accuracy=63.5\n",
      " for epoch 3 and batch  160, test loss = 0.9466632008552551 and the accuracy=63.25\n",
      " for epoch 3 and batch  180, test loss = 1.1380938291549683 and the accuracy=63.44444274902344\n",
      " for epoch 3 and batch  200, test loss = 1.0272138118743896 and the accuracy=63.54999923706055\n",
      " for epoch 3 and batch  220, test loss = 0.7396758794784546 and the accuracy=63.6363639831543\n",
      " for epoch 3 and batch  240, test loss = 1.7346012592315674 and the accuracy=63.70833206176758\n",
      " for epoch 3 and batch  260, test loss = 0.9163813591003418 and the accuracy=63.653846740722656\n",
      " for epoch 3 and batch  280, test loss = 1.128942847251892 and the accuracy=63.60714340209961\n",
      " for epoch 3 and batch  300, test loss = 1.1213090419769287 and the accuracy=63.733333587646484\n",
      " for epoch 3 and batch  320, test loss = 2.291348457336426 and the accuracy=63.46875\n",
      " for epoch 3 and batch  340, test loss = 1.7589266300201416 and the accuracy=62.382354736328125\n",
      " for epoch 3 and batch  360, test loss = 1.7381494045257568 and the accuracy=61.55555725097656\n",
      " for epoch 3 and batch  380, test loss = 1.789266586303711 and the accuracy=60.8684196472168\n",
      " for epoch 3 and batch  400, test loss = 2.1851165294647217 and the accuracy=60.025001525878906\n",
      " for epoch 3 and batch  420, test loss = 1.8375442028045654 and the accuracy=59.35714340209961\n",
      " for epoch 3 and batch  440, test loss = 2.0075018405914307 and the accuracy=58.84090805053711\n",
      " for epoch 3 and batch  460, test loss = 1.861393928527832 and the accuracy=58.30434799194336\n",
      " for epoch 3 and batch  480, test loss = 1.9863927364349365 and the accuracy=57.8125\n",
      " for epoch 3 and batch  500, test loss = 1.8775914907455444 and the accuracy=57.34000015258789\n",
      " for epoch 3 and batch  520, test loss = 2.241899013519287 and the accuracy=56.903846740722656\n",
      " for epoch 3 and batch  540, test loss = 1.9958051443099976 and the accuracy=56.61111068725586\n",
      " for epoch 3 and batch  560, test loss = 2.515810966491699 and the accuracy=56.32143020629883\n",
      " for epoch 3 and batch  580, test loss = 1.8664371967315674 and the accuracy=56.120689392089844\n",
      " for epoch 3 and batch  600, test loss = 2.68111515045166 and the accuracy=55.68333435058594\n",
      " for epoch 3 and batch  620, test loss = 1.4972572326660156 and the accuracy=55.467742919921875\n",
      " for epoch 4 and batch  20, training loss = 0.09118670225143433 and the accuracy=97.01000213623047\n",
      " for epoch 4 and batch  40, training loss = 0.05293390154838562 and the accuracy=96.71499633789062\n",
      " for epoch 4 and batch  60, training loss = 0.08966037631034851 and the accuracy=96.75666809082031\n",
      " for epoch 4 and batch  20, test loss = 1.9813833236694336 and the accuracy=53.5\n",
      " for epoch 4 and batch  40, test loss = 2.1287026405334473 and the accuracy=53.25\n",
      " for epoch 4 and batch  60, test loss = 1.6981728076934814 and the accuracy=52.5\n",
      " for epoch 4 and batch  80, test loss = 1.6303470134735107 and the accuracy=52.125\n",
      " for epoch 4 and batch  100, test loss = 1.3937090635299683 and the accuracy=52.5\n",
      " for epoch 4 and batch  120, test loss = 2.155565023422241 and the accuracy=52.91666793823242\n",
      " for epoch 4 and batch  140, test loss = 1.730708360671997 and the accuracy=53.35714340209961\n",
      " for epoch 4 and batch  160, test loss = 1.9231233596801758 and the accuracy=53.3125\n",
      " for epoch 4 and batch  180, test loss = 1.947576880455017 and the accuracy=53.61111068725586\n",
      " for epoch 4 and batch  200, test loss = 1.8707952499389648 and the accuracy=53.25\n",
      " for epoch 4 and batch  220, test loss = 0.9177389144897461 and the accuracy=53.1363639831543\n",
      " for epoch 4 and batch  240, test loss = 2.3178298473358154 and the accuracy=53.25\n",
      " for epoch 4 and batch  260, test loss = 1.5446336269378662 and the accuracy=53.11538314819336\n",
      " for epoch 4 and batch  280, test loss = 1.932572364807129 and the accuracy=53.14285659790039\n",
      " for epoch 4 and batch  300, test loss = 1.6709649562835693 and the accuracy=53.20000076293945\n",
      " for epoch 4 and batch  320, test loss = 1.349719762802124 and the accuracy=53.5625\n",
      " for epoch 4 and batch  340, test loss = 1.9950824975967407 and the accuracy=53.79411697387695\n",
      " for epoch 4 and batch  360, test loss = 1.1899573802947998 and the accuracy=54.16666793823242\n",
      " for epoch 4 and batch  380, test loss = 1.4225037097930908 and the accuracy=54.394737243652344\n",
      " for epoch 4 and batch  400, test loss = 1.6425281763076782 and the accuracy=54.45000076293945\n",
      " for epoch 4 and batch  420, test loss = 1.3696187734603882 and the accuracy=54.619049072265625\n",
      " for epoch 4 and batch  440, test loss = 1.7932840585708618 and the accuracy=54.90909194946289\n",
      " for epoch 4 and batch  460, test loss = 1.609705924987793 and the accuracy=55.08695602416992\n",
      " for epoch 4 and batch  480, test loss = 1.2907803058624268 and the accuracy=55.20833206176758\n",
      " for epoch 4 and batch  500, test loss = 1.7180631160736084 and the accuracy=55.20000076293945\n",
      " for epoch 4 and batch  520, test loss = 1.7578204870224 and the accuracy=55.32692337036133\n",
      " for epoch 4 and batch  540, test loss = 1.6391041278839111 and the accuracy=55.61111068725586\n",
      " for epoch 4 and batch  560, test loss = 1.9397300481796265 and the accuracy=55.76785659790039\n",
      " for epoch 4 and batch  580, test loss = 1.5931923389434814 and the accuracy=55.89655303955078\n",
      " for epoch 4 and batch  600, test loss = 2.009920597076416 and the accuracy=55.849998474121094\n",
      " for epoch 4 and batch  620, test loss = 1.68076491355896 and the accuracy=55.967742919921875\n",
      " for epoch 5 and batch  20, training loss = 0.06663493812084198 and the accuracy=96.4000015258789\n",
      " for epoch 5 and batch  40, training loss = 0.07707854360342026 and the accuracy=96.55500030517578\n",
      " for epoch 5 and batch  60, training loss = 0.08232851326465607 and the accuracy=96.6500015258789\n",
      " for epoch 5 and batch  20, test loss = 2.0037238597869873 and the accuracy=53.5\n",
      " for epoch 5 and batch  40, test loss = 2.4003512859344482 and the accuracy=53.0\n",
      " for epoch 5 and batch  60, test loss = 1.819649338722229 and the accuracy=52.16666793823242\n",
      " for epoch 5 and batch  80, test loss = 1.9760549068450928 and the accuracy=51.5\n",
      " for epoch 5 and batch  100, test loss = 1.7106441259384155 and the accuracy=51.70000076293945\n",
      " for epoch 5 and batch  120, test loss = 2.059821844100952 and the accuracy=52.33333206176758\n",
      " for epoch 5 and batch  140, test loss = 1.977460503578186 and the accuracy=52.92856979370117\n",
      " for epoch 5 and batch  160, test loss = 1.8517255783081055 and the accuracy=52.75\n",
      " for epoch 5 and batch  180, test loss = 1.6132404804229736 and the accuracy=53.0\n",
      " for epoch 5 and batch  200, test loss = 1.787614107131958 and the accuracy=52.75\n",
      " for epoch 5 and batch  220, test loss = 1.1493089199066162 and the accuracy=52.59090805053711\n",
      " for epoch 5 and batch  240, test loss = 2.174572706222534 and the accuracy=52.70833206176758\n",
      " for epoch 5 and batch  260, test loss = 1.446228265762329 and the accuracy=52.57692337036133\n",
      " for epoch 5 and batch  280, test loss = 1.6670290231704712 and the accuracy=52.67856979370117\n",
      " for epoch 5 and batch  300, test loss = 1.9586305618286133 and the accuracy=52.70000076293945\n",
      " for epoch 5 and batch  320, test loss = 1.366802453994751 and the accuracy=52.96875\n",
      " for epoch 5 and batch  340, test loss = 1.6444404125213623 and the accuracy=53.17647171020508\n",
      " for epoch 5 and batch  360, test loss = 1.3480350971221924 and the accuracy=53.61111068725586\n",
      " for epoch 5 and batch  380, test loss = 1.0364680290222168 and the accuracy=53.94736862182617\n",
      " for epoch 5 and batch  400, test loss = 1.620002031326294 and the accuracy=54.125\n",
      " for epoch 5 and batch  420, test loss = 1.6701624393463135 and the accuracy=54.33333206176758\n",
      " for epoch 5 and batch  440, test loss = 1.5875434875488281 and the accuracy=54.681819915771484\n",
      " for epoch 5 and batch  460, test loss = 1.37109375 and the accuracy=54.869564056396484\n",
      " for epoch 5 and batch  480, test loss = 1.2875361442565918 and the accuracy=55.125\n",
      " for epoch 5 and batch  500, test loss = 1.3349817991256714 and the accuracy=55.119998931884766\n",
      " for epoch 5 and batch  520, test loss = 1.5910978317260742 and the accuracy=55.230770111083984\n",
      " for epoch 5 and batch  540, test loss = 1.840364694595337 and the accuracy=55.53703689575195\n",
      " for epoch 5 and batch  560, test loss = 1.838021993637085 and the accuracy=55.67856979370117\n",
      " for epoch 5 and batch  580, test loss = 1.9456783533096313 and the accuracy=55.81034469604492\n",
      " for epoch 5 and batch  600, test loss = 2.641568660736084 and the accuracy=55.86666488647461\n",
      " for epoch 5 and batch  620, test loss = 1.2313991785049438 and the accuracy=56.0\n",
      " for epoch 6 and batch  20, training loss = 0.04991016536951065 and the accuracy=96.54000091552734\n",
      " for epoch 6 and batch  40, training loss = 0.07223646342754364 and the accuracy=96.38999938964844\n",
      " for epoch 6 and batch  60, training loss = 0.055212654173374176 and the accuracy=96.48666381835938\n",
      " for epoch 6 and batch  20, test loss = 1.843454360961914 and the accuracy=59.5\n",
      " for epoch 6 and batch  40, test loss = 1.5813515186309814 and the accuracy=58.25\n",
      " for epoch 6 and batch  60, test loss = 1.0587193965911865 and the accuracy=58.16666793823242\n",
      " for epoch 6 and batch  80, test loss = 1.013956904411316 and the accuracy=57.75\n",
      " for epoch 6 and batch  100, test loss = 0.8670490384101868 and the accuracy=58.099998474121094\n",
      " for epoch 6 and batch  120, test loss = 1.416900873184204 and the accuracy=58.75\n",
      " for epoch 6 and batch  140, test loss = 1.666252851486206 and the accuracy=59.0\n",
      " for epoch 6 and batch  160, test loss = 1.5146806240081787 and the accuracy=59.0\n",
      " for epoch 6 and batch  180, test loss = 0.9754370450973511 and the accuracy=59.33333206176758\n",
      " for epoch 6 and batch  200, test loss = 1.2043523788452148 and the accuracy=59.25\n",
      " for epoch 6 and batch  220, test loss = 0.6420267224311829 and the accuracy=59.318180084228516\n",
      " for epoch 6 and batch  240, test loss = 1.5845364332199097 and the accuracy=59.25\n",
      " for epoch 6 and batch  260, test loss = 0.9791229367256165 and the accuracy=59.230770111083984\n",
      " for epoch 6 and batch  280, test loss = 1.3999884128570557 and the accuracy=59.39285659790039\n",
      " for epoch 6 and batch  300, test loss = 1.300221562385559 and the accuracy=59.43333435058594\n",
      " for epoch 6 and batch  320, test loss = 1.5609443187713623 and the accuracy=59.4375\n",
      " for epoch 6 and batch  340, test loss = 1.5214283466339111 and the accuracy=58.97058868408203\n",
      " for epoch 6 and batch  360, test loss = 1.7881063222885132 and the accuracy=58.72222137451172\n",
      " for epoch 6 and batch  380, test loss = 1.505869746208191 and the accuracy=58.44736862182617\n",
      " for epoch 6 and batch  400, test loss = 1.841517686843872 and the accuracy=58.0\n",
      " for epoch 6 and batch  420, test loss = 1.6961231231689453 and the accuracy=57.66666793823242\n",
      " for epoch 6 and batch  440, test loss = 1.9791450500488281 and the accuracy=57.54545593261719\n",
      " for epoch 6 and batch  460, test loss = 1.7606359720230103 and the accuracy=57.21739196777344\n",
      " for epoch 6 and batch  480, test loss = 1.590084195137024 and the accuracy=56.97916793823242\n",
      " for epoch 6 and batch  500, test loss = 1.6554880142211914 and the accuracy=56.7599983215332\n",
      " for epoch 6 and batch  520, test loss = 1.8377174139022827 and the accuracy=56.403846740722656\n",
      " for epoch 6 and batch  540, test loss = 2.1292030811309814 and the accuracy=56.314815521240234\n",
      " for epoch 6 and batch  560, test loss = 2.0125534534454346 and the accuracy=56.19643020629883\n",
      " for epoch 6 and batch  580, test loss = 2.1520845890045166 and the accuracy=56.08620834350586\n",
      " for epoch 6 and batch  600, test loss = 2.4904181957244873 and the accuracy=55.86666488647461\n",
      " for epoch 6 and batch  620, test loss = 1.9966388940811157 and the accuracy=55.709678649902344\n",
      " for epoch 7 and batch  20, training loss = 0.08446004241704941 and the accuracy=96.97000122070312\n",
      " for epoch 7 and batch  40, training loss = 0.06622261554002762 and the accuracy=97.03500366210938\n",
      " for epoch 7 and batch  60, training loss = 0.0725170373916626 and the accuracy=96.91999816894531\n",
      " for epoch 7 and batch  20, test loss = 1.9412987232208252 and the accuracy=49.5\n",
      " for epoch 7 and batch  40, test loss = 2.266388416290283 and the accuracy=49.75\n",
      " for epoch 7 and batch  60, test loss = 1.7615430355072021 and the accuracy=49.83333206176758\n",
      " for epoch 7 and batch  80, test loss = 1.6564466953277588 and the accuracy=49.375\n",
      " for epoch 7 and batch  100, test loss = 1.7190243005752563 and the accuracy=49.599998474121094\n",
      " for epoch 7 and batch  120, test loss = 2.3872156143188477 and the accuracy=49.75\n",
      " for epoch 7 and batch  140, test loss = 2.475648880004883 and the accuracy=49.78571319580078\n",
      " for epoch 7 and batch  160, test loss = 2.1808884143829346 and the accuracy=49.5625\n",
      " for epoch 7 and batch  180, test loss = 1.968226432800293 and the accuracy=49.77777862548828\n",
      " for epoch 7 and batch  200, test loss = 2.0890159606933594 and the accuracy=49.54999923706055\n",
      " for epoch 7 and batch  220, test loss = 1.0103561878204346 and the accuracy=49.59090805053711\n",
      " for epoch 7 and batch  240, test loss = 2.1342434883117676 and the accuracy=49.625\n",
      " for epoch 7 and batch  260, test loss = 1.7750647068023682 and the accuracy=49.5\n",
      " for epoch 7 and batch  280, test loss = 2.096531391143799 and the accuracy=49.53571319580078\n",
      " for epoch 7 and batch  300, test loss = 1.9247667789459229 and the accuracy=49.53333282470703\n",
      " for epoch 7 and batch  320, test loss = 1.0554959774017334 and the accuracy=50.1875\n",
      " for epoch 7 and batch  340, test loss = 1.5937011241912842 and the accuracy=50.882354736328125\n",
      " for epoch 7 and batch  360, test loss = 1.1776759624481201 and the accuracy=51.66666793823242\n",
      " for epoch 7 and batch  380, test loss = 1.0163437128067017 and the accuracy=52.26315689086914\n",
      " for epoch 7 and batch  400, test loss = 1.6202728748321533 and the accuracy=52.599998474121094\n",
      " for epoch 7 and batch  420, test loss = 1.4182443618774414 and the accuracy=52.97618865966797\n",
      " for epoch 7 and batch  440, test loss = 1.7749946117401123 and the accuracy=53.477272033691406\n",
      " for epoch 7 and batch  460, test loss = 1.1305179595947266 and the accuracy=53.84782791137695\n",
      " for epoch 7 and batch  480, test loss = 1.08224356174469 and the accuracy=54.1875\n",
      " for epoch 7 and batch  500, test loss = 1.6388181447982788 and the accuracy=54.439998626708984\n",
      " for epoch 7 and batch  520, test loss = 2.0821452140808105 and the accuracy=54.769229888916016\n",
      " for epoch 7 and batch  540, test loss = 1.815346121788025 and the accuracy=55.22222137451172\n",
      " for epoch 7 and batch  560, test loss = 1.5935180187225342 and the accuracy=55.53571319580078\n",
      " for epoch 7 and batch  580, test loss = 1.3162598609924316 and the accuracy=55.844825744628906\n",
      " for epoch 7 and batch  600, test loss = 2.372593402862549 and the accuracy=55.983333587646484\n",
      " for epoch 7 and batch  620, test loss = 1.5943286418914795 and the accuracy=56.24193572998047\n",
      " for epoch 8 and batch  20, training loss = 0.059718020260334015 and the accuracy=97.20999908447266\n",
      " for epoch 8 and batch  40, training loss = 0.07389020174741745 and the accuracy=96.98999786376953\n",
      " for epoch 8 and batch  60, training loss = 0.068966805934906 and the accuracy=96.95999908447266\n",
      " for epoch 8 and batch  20, test loss = 1.9466207027435303 and the accuracy=54.0\n",
      " for epoch 8 and batch  40, test loss = 2.0086543560028076 and the accuracy=53.25\n",
      " for epoch 8 and batch  60, test loss = 1.5111219882965088 and the accuracy=52.66666793823242\n",
      " for epoch 8 and batch  80, test loss = 1.6973419189453125 and the accuracy=51.75\n",
      " for epoch 8 and batch  100, test loss = 1.3647634983062744 and the accuracy=52.099998474121094\n",
      " for epoch 8 and batch  120, test loss = 2.0941555500030518 and the accuracy=52.91666793823242\n",
      " for epoch 8 and batch  140, test loss = 1.9247181415557861 and the accuracy=53.14285659790039\n",
      " for epoch 8 and batch  160, test loss = 1.784163236618042 and the accuracy=53.0\n",
      " for epoch 8 and batch  180, test loss = 1.5276936292648315 and the accuracy=53.11111068725586\n",
      " for epoch 8 and batch  200, test loss = 1.7715814113616943 and the accuracy=52.95000076293945\n",
      " for epoch 8 and batch  220, test loss = 0.8483255505561829 and the accuracy=52.727272033691406\n",
      " for epoch 8 and batch  240, test loss = 2.53045392036438 and the accuracy=52.875\n",
      " for epoch 8 and batch  260, test loss = 1.5917656421661377 and the accuracy=52.69230651855469\n",
      " for epoch 8 and batch  280, test loss = 2.018383264541626 and the accuracy=52.71428680419922\n",
      " for epoch 8 and batch  300, test loss = 1.637804388999939 and the accuracy=52.766666412353516\n",
      " for epoch 8 and batch  320, test loss = 1.459808111190796 and the accuracy=53.21875\n",
      " for epoch 8 and batch  340, test loss = 1.7579166889190674 and the accuracy=53.67647171020508\n",
      " for epoch 8 and batch  360, test loss = 1.6013027429580688 and the accuracy=54.13888931274414\n",
      " for epoch 8 and batch  380, test loss = 1.1778327226638794 and the accuracy=54.5\n",
      " for epoch 8 and batch  400, test loss = 1.8399101495742798 and the accuracy=54.57500076293945\n",
      " for epoch 8 and batch  420, test loss = 1.4647364616394043 and the accuracy=54.761905670166016\n",
      " for epoch 8 and batch  440, test loss = 1.6296539306640625 and the accuracy=55.1363639831543\n",
      " for epoch 8 and batch  460, test loss = 1.1091690063476562 and the accuracy=55.30434799194336\n",
      " for epoch 8 and batch  480, test loss = 1.6361726522445679 and the accuracy=55.47916793823242\n",
      " for epoch 8 and batch  500, test loss = 1.4568800926208496 and the accuracy=55.52000045776367\n",
      " for epoch 8 and batch  520, test loss = 2.200465679168701 and the accuracy=55.57692337036133\n",
      " for epoch 8 and batch  540, test loss = 1.9178968667984009 and the accuracy=55.87036895751953\n",
      " for epoch 8 and batch  560, test loss = 1.758378267288208 and the accuracy=56.05356979370117\n",
      " for epoch 8 and batch  580, test loss = 1.7295080423355103 and the accuracy=56.17241287231445\n",
      " for epoch 8 and batch  600, test loss = 2.6889572143554688 and the accuracy=56.150001525878906\n",
      " for epoch 8 and batch  620, test loss = 1.548708200454712 and the accuracy=56.30644989013672\n",
      " for epoch 9 and batch  20, training loss = 0.0524323545396328 and the accuracy=96.63999938964844\n",
      " for epoch 9 and batch  40, training loss = 0.08370151370763779 and the accuracy=96.91999816894531\n",
      " for epoch 9 and batch  60, training loss = 0.05743371695280075 and the accuracy=96.91666412353516\n",
      " for epoch 9 and batch  20, test loss = 1.7390245199203491 and the accuracy=61.0\n",
      " for epoch 9 and batch  40, test loss = 1.6880314350128174 and the accuracy=59.5\n",
      " for epoch 9 and batch  60, test loss = 1.0075204372406006 and the accuracy=59.0\n",
      " for epoch 9 and batch  80, test loss = 1.1691566705703735 and the accuracy=58.375\n",
      " for epoch 9 and batch  100, test loss = 0.967337429523468 and the accuracy=58.5\n",
      " for epoch 9 and batch  120, test loss = 1.8741490840911865 and the accuracy=58.91666793823242\n",
      " for epoch 9 and batch  140, test loss = 1.6080904006958008 and the accuracy=59.42856979370117\n",
      " for epoch 9 and batch  160, test loss = 1.5064988136291504 and the accuracy=59.25\n",
      " for epoch 9 and batch  180, test loss = 1.382095217704773 and the accuracy=59.55555725097656\n",
      " for epoch 9 and batch  200, test loss = 1.7633333206176758 and the accuracy=59.650001525878906\n",
      " for epoch 9 and batch  220, test loss = 0.7024315595626831 and the accuracy=59.59090805053711\n",
      " for epoch 9 and batch  240, test loss = 1.805150032043457 and the accuracy=59.45833206176758\n",
      " for epoch 9 and batch  260, test loss = 1.3362761735916138 and the accuracy=59.38461685180664\n",
      " for epoch 9 and batch  280, test loss = 1.4463143348693848 and the accuracy=59.35714340209961\n",
      " for epoch 9 and batch  300, test loss = 1.6376399993896484 and the accuracy=59.43333435058594\n",
      " for epoch 9 and batch  320, test loss = 1.5258972644805908 and the accuracy=59.3125\n",
      " for epoch 9 and batch  340, test loss = 1.9362552165985107 and the accuracy=58.735294342041016\n",
      " for epoch 9 and batch  360, test loss = 1.737247109413147 and the accuracy=58.58333206176758\n",
      " for epoch 9 and batch  380, test loss = 1.6537628173828125 and the accuracy=58.3684196472168\n",
      " for epoch 9 and batch  400, test loss = 2.0266261100769043 and the accuracy=57.92499923706055\n",
      " for epoch 9 and batch  420, test loss = 2.231293201446533 and the accuracy=57.619049072265625\n",
      " for epoch 9 and batch  440, test loss = 2.1998119354248047 and the accuracy=57.3863639831543\n",
      " for epoch 9 and batch  460, test loss = 1.7524299621582031 and the accuracy=57.173912048339844\n",
      " for epoch 9 and batch  480, test loss = 1.6262744665145874 and the accuracy=57.02083206176758\n",
      " for epoch 9 and batch  500, test loss = 2.1982903480529785 and the accuracy=56.720001220703125\n",
      " for epoch 9 and batch  520, test loss = 2.520479202270508 and the accuracy=56.403846740722656\n",
      " for epoch 9 and batch  540, test loss = 2.317387104034424 and the accuracy=56.38888931274414\n",
      " for epoch 9 and batch  560, test loss = 1.9173485040664673 and the accuracy=56.25\n",
      " for epoch 9 and batch  580, test loss = 2.211188793182373 and the accuracy=56.08620834350586\n",
      " for epoch 9 and batch  600, test loss = 2.4843876361846924 and the accuracy=55.79999923706055\n",
      " for epoch 9 and batch  620, test loss = 1.626264214515686 and the accuracy=55.790321350097656\n"
     ]
    }
   ],
   "source": [
    "train_epoch_loss=[]\n",
    "test_epoch_loss=[]\n",
    "start_time=time.time()\n",
    "for e in range(epochs):\n",
    "    train_batch_loss=[]\n",
    "    test_batch_loss=[]\n",
    "    train_acc=0\n",
    "    test_acc=0\n",
    "    for batch, (x_train, y_train) in enumerate(train_loader):\n",
    "        batch+=1\n",
    "        y_pred_train=resnet50_model(x_train)\n",
    "#         print(y_pred_train)\n",
    "#         print(y_pred_train.shape)\n",
    "        train_acc+=(y_pred_train.argmax(dim=1)==y_train).sum()\n",
    "        train_loss=criterion(y_pred_train, y_train)\n",
    "#         print(train_loss)\n",
    "        if batch%20==0:\n",
    "            print(f' for epoch {e} and batch  {batch}, training loss = {train_loss} and the accuracy={train_acc*100/(batch*500)}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    train_epoch_loss.append(train_acc)\n",
    "    with torch.no_grad():\n",
    "        for batch, (x_test, y_test) in enumerate(test_loader):\n",
    "            batch+=1\n",
    "            y_pred_test=resnet50_model(x_test)\n",
    "            test_acc+=(y_pred_test.argmax(dim=1)==y_test).sum()\n",
    "            test_loss=criterion(y_pred_test, y_test)\n",
    "            if batch%20==0:\n",
    "                print(f' for epoch {e} and batch  {batch}, test loss = {test_loss} and the accuracy={test_acc*100/(batch*10)}')\n",
    "    test_epoch_loss.append(test_acc)\n",
    "duration=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet50_model.state_dict(),'swami_resnet50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\to do\\\\pytorch-for-deep-learning-with-python-bootcamp\\\\001 PYTORCH_NOTEBOOKS\\\\PYTORCH_NOTEBOOKS\\\\03-CNN-Convolutional-Neural-Networks'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_=[x.item() for x in train_epoch_loss]\n",
    "test_loss_=[x.item()  for x in test_epoch_loss]\n",
    "# acc_train_=[x.item()  for x in acc_train]\n",
    "# acc_test_=[x.item()  for x in acc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_custom={'train_losses':train_loss_, 'test_losses':test_loss_,'epochs':epochs,'time':duration}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json = json.dumps(losses_custom)\n",
    "f = open(\"Swami_resnet50.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
